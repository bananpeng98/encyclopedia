#+title: Kruskal-Wallis test
#+roam_tags: statistics kruskal wallis test nonparametric

- tags :: [[file:20210219102643-statistics.org][Statistics]], [[file:20210219100256-hypothesis_test.org][Hypothesis test]]

#+call: init()

#+begin_src jupyter-python
from scipy.stats import rankdata
import numpy as np
from sympy import *
from sympy.stats import *
from pyorg.latex import *
from encyclopedia.statistics import *
from encyclopedia.hypothesis_test import *
#+end_src

#+RESULTS:

* Kruskal-Wallis test
The Kruskal-Wallis test is a non-parametric, one-way analysis of variance on
ranks, [[file:20210219100256-hypothesis_test.org][hypothesis test]] with the assumption of independent observations. It does
not make any assumptions about the distribution.

To perform this test, we rank the pooled sample
#+begin_src jupyter-python
N, I = symbols('N I', integer=True, positive=True)
K = symbols('K')
i, j, idot, B = symbols('i j . B', cls=Idx)
R, Y, J, SS = symbols('R Y J SS', cls=IndexedBase)
LEq(LMean(R[i, j]), Latex("the rank of ", Y[i, j], " in the combined sample"))
#+end_src

#+RESULTS:
:RESULTS:
\begin{equation}\overline {R_{ij}}=\mathtt{\text{the rank of }}{Y_{ij}}\mathtt{\text{ in the combined sample}}\end{equation}
:END:

We use the following notation
#+begin_src jupyter-python
Rid_eq = LEq(LMean(R[i, idot]), (1/J[i])*Sum(R[i, j], (j, 0, J[i]-1)))
Rid_eq
#+end_src

#+RESULTS:
:RESULTS:
\begin{equation}\overline {R_{i.}}=\frac{\sum_{j=0}^{{J_{i}} - 1} {R_{ij}}}{{J_{i}}}\end{equation}
:END:

#+begin_src jupyter-python
Rdd_eq = LEq(LMean(R[idot, idot]), (1/N)*Sum(Sum(R[i, j], (j, 0, J[i]-1)), (i, 0, I-1)), (N+1)/2)
Rdd_eq
#+end_src

#+RESULTS:
:RESULTS:
\begin{equation}\overline {R_{..}}=\frac{\sum_{\substack{0 \leq j \leq {J_{i}} - 1\\0 \leq i \leq I - 1}} {R_{ij}}}{N}=\frac{N}{2} + \frac{1}{2}\end{equation}
:END:

#+begin_src jupyter-python
SSB_eq = LEq(SS[B], Sum(J[i]*(LMean(R[i,idot])-LMean(R[idot,idot]))**2, (i, 0, I-1)))
SSB_eq
#+end_src

#+RESULTS:
:RESULTS:
\begin{equation}{SS_{B}}=\sum_{i=0}^{I - 1} {J_{i}} \left(- \overline {R_{..}} + \overline {R_{i.}}\right)^{2}\end{equation}
:END:

#+begin_src jupyter-python
K_eq = LEq(K, SS[B]*12/(N*(N+1)))
K_eq
#+end_src

#+RESULTS:
:RESULTS:
\begin{equation}K=\frac{12 {SS_{B}}}{N \left(N + 1\right)}\end{equation}
:END:

#+begin_src jupyter-python :exports none
K_expanded = K_eq.rhs.subs(SS[B], SSB_eq.rhs).subs(Rdd_eq.lhs, Rdd_eq.rhs).replace(Rid_eq.lhs, Rid_eq.rhs)
K_lam = lambdify((N, I, J, R), K_expanded, 'numpy')

K_lam(6, 3, np.array([2, 2, 2]), np.array([[1, 2], [4, 5], [6, 7]]))
#+end_src

#+RESULTS:
: 8.0

** Example
#+begin_src jupyter-python
labs = 7
samples = 10
dof = labs-1
data = np.array([[4.13, 4.07, 4.04, 4.07, 4.05, 4.04, 4.02, 4.06, 4.10, 4.04],
                 [3.86, 3.85, 4.08, 4.11, 4.08, 4.01, 4.02, 4.04, 3.97, 3.95],
                 [4.00, 4.02, 4.01, 4.01, 4.04, 3.99, 4.03, 3.97, 3.98, 3.98],
                 [3.88, 3.88, 3.91, 3.95, 3.92, 3.97, 3.92, 3.90, 3.97, 3.90],
                 [4.02, 3.95, 4.02, 3.89, 3.91, 4.01, 3.89, 3.89, 3.99, 4.00],
                 [4.02, 3.86, 3.96, 3.97, 4.00, 3.82, 3.98, 3.99, 4.02, 3.93],
                 [4.00, 4.02, 4.03, 4.04, 4.10, 3.81, 3.91, 3.96, 4.05, 4.06]])
data += np.random.normal(0, 0.01, size=data.shape)
data = data.round(3)
def to_table(data):
    return [[f"Lab {i+1}" for i in range(labs)], None]+data.T.tolist()
to_table(data)
#+end_src

#+RESULTS:
| Lab 1 | Lab 2 | Lab 3 | Lab 4 | Lab 5 | Lab 6 | Lab 7 |
|-------+-------+-------+-------+-------+-------+-------|
| 4.125 | 3.876 | 3.996 | 3.874 | 4.002 | 4.012 | 3.999 |
| 4.069 | 3.843 | 4.022 | 3.866 | 3.947 | 3.865 | 3.997 |
| 4.045 | 4.074 | 4.016 | 3.899 | 4.013 | 3.939 | 4.035 |
| 4.084 | 4.092 | 4.003 | 3.948 |  3.91 | 3.963 | 4.046 |
| 4.054 | 4.071 | 4.025 | 3.935 | 3.925 | 4.005 | 4.117 |
| 4.049 | 3.999 | 4.005 | 3.973 | 4.014 | 3.811 | 3.794 |
| 4.021 | 4.015 |  4.03 | 3.919 | 3.886 | 3.979 | 3.909 |
| 4.035 | 4.055 | 3.987 | 3.888 | 3.895 | 4.016 | 3.976 |
| 4.113 | 3.968 | 3.975 | 3.974 | 3.989 | 4.025 | 4.056 |
| 4.054 | 3.957 | 3.965 | 3.902 | 3.991 | 3.926 | 4.062 |

#+begin_src jupyter-python
R_n = rankdata(data).reshape([labs, samples])
K_n = K_lam(labs*samples, labs, np.ones([labs], dtype=int)*samples, R_n)
LEq(K, K_n)
#+end_src

#+RESULTS:
:RESULTS:
\begin{equation}K=29.8338832997988\end{equation}
:END:

#+begin_src jupyter-python
V = {
    K: K_n,
    alpha: 0.005
}
X = ChiSquared(f'\\chi^2_{dof}', dof)
p, x = symbols('p x')
p_value = calculate_p_value(K, X, right_tailed)
hypothesis = hypothesis_test("there is no difference between labs",
                             "there is a difference between labs",
                             p_value,
                             V)
hypothesis[0]
#+end_src

#+RESULTS:
:RESULTS:
\begin{equation}\begin{cases} H_{0}:\mathtt{\text{there is no difference between labs}} & \text{for}\: p\geq\alpha \\H_{1}:\mathtt{\text{there is a difference between labs}} & \text{otherwise} \end{cases}\end{equation}
:END:


#+begin_src jupyter-python
p_value.subs(V).evalf()
#+end_src

#+RESULTS:
:RESULTS:
\begin{equation}\begin{aligned}
p&=P[T \geq t]=\\
&=P[\chi^{2}_{6} \geq 29.8338832997988]=\\
&=4.22721801901717 \cdot 10^{-5}
\end{aligned}\end{equation}
:END:

#+begin_src jupyter-python
hypothesis[-1]
#+end_src

#+RESULTS:
:RESULTS:
\begin{equation}\begin{aligned}
p < \alpha&\Rightarrow 4.22721801901717 \cdot 10^{-5}<0.005\Rightarrow \\
&\Rightarrow H_{1}:\mathtt{\text{there is a difference between labs}}
\end{aligned}\end{equation}
:END:
